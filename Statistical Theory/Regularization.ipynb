{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression (Hoerl and Kennard, 1970)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the linear model with an intercept term $ Y=\\beta_{0}+X\\beta+\\epsilon$ .When some of the columns of X\n",
    "  are nearly collinear (as is likely when $p$\n",
    "  is nearly as large as n), the determinant of $X^{T}X $\n",
    " , which is the square of the volume of the parallelepiped whose edges are the columns of $X$\n",
    " , is nearly 0. Thus, since a determinant is the product of the eigenvalues, at least one of the eigenvalues of $ \\left(X^{T}X\\right)^{-1} $\n",
    " is very large. But  $$ \\hat{\\beta}\\sim N_{p}\\left(\\beta,\\,\\sigma^{2}\\left(X^{T}X\\right)^{-1}\\right) $$\n",
    " , at least when the columns of X\n",
    "  are orthogonal to $ (1,1,1,...,1,1)^{T} $\n",
    " , and the sum of the eigenvalues is the trace, so at least one of the components of \\hat{\\beta}\n",
    "  has very large variance. We therefore seek to shrink \\hat{\\beta}\n",
    "  towards the origin. This will introduce a bias, but we hope it will be more than compensated by a reduction in variance. \n",
    "\n",
    "For fixed $\\lambda>0 $\n",
    " , the ridge regression estimator is  $$ \\hat{\\beta}_{\\lambda}^{R} $$\n",
    " , where $$ \\left(\\hat{\\beta}_{0},\\hat{\\beta}_{\\lambda}^{R}\\right) $$\n",
    "  minimises $$ Q_{2}(\\beta_{0},\\beta)=\\sum_{i=1}^{n}\\left(Y_{i}-\\beta_{0}-\\sum_{j=1}^{p}x_{ij}\\beta_{j}\\right)^{2}+\\lambda\\sum_{j=1}^{p}\\beta_{j}^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In that case, $\\hat{\\beta}_{\\lambda}^{R}=(X^{T}X+\\lambda I)^{-1}X^{T}Y $ (see example sheet)\n",
    "\n",
    "Observe that $ \\hat{\\beta}_{\\lambda}^{R}$ \n",
    "  also minimises $$ \\sum_{i=1}^{n}\\left(Y_{i}-\\sum_{j=1}^{p}x_{ij}\\beta_{j}\\right)^{2} $$\n",
    "  subject to  $ \\sum_{j=1}^{p}\\beta_{j}^{2}\\leq s $\n",
    "  where $ s=s(\\lambda) $ is a bijective function. It can also be motivated in a Bayesian way as the maximum a posteriori (MAP) and posterior mean estimators of \\beta\n",
    "  under a N_{p}\\left(0,\\,\\frac{1}{\\lambda}I\\right)\n",
    "  prior. \n",
    "\n",
    "In order to study the Mean Squared Error (MSE) properties of $ \\hat{\\beta}_{\\lambda}^{R} $\n",
    " , we define $V=\\left(I+\\lambda\\left(X^{T}X\\right)^{-1}\\right)^{-1} $\n",
    "  and $W=\\left(X^{T}X+\\lambda I\\right)^{-1}$\n",
    " , so that $ \\hat{\\beta}_{\\lambda}^{R}=\\left(X^{T}X+\\lambda I\\right)^{-1}X^{T}Y=WX^{T}Y=V\\hat{\\beta} $\n",
    " \n",
    "\n",
    "and  $$ V-I=\\left(I+\\lambda(X^{T}X)^{-1}\\right)^{-1}-I=WX^{T}X-I=W\\left(X^{T}X-W^{-1}\\right)=-\\lambda W $$\n",
    "\n",
    "Assume that X\n",
    "  has full rank p (in particular, $ p\\leq n $\n",
    " ), and write $\\mu_{1}\\geq...\\geq\\mu_{p}>0 $\n",
    "  for the eigenvalues of  $X^{T}X$\n",
    " . Let P\n",
    "  be an orthogonal matrix such that $P^{T}X^{T}XP=D\\equiv\\mbox{diag}(\\mu_{1},...,\\mu_{p}) $\n",
    " . Then $$ \\det\\left(W-\\frac{1}{\\mu_{j}+\\lambda}I\\right)\t=\t\\det\\left(\\left(PDP^{T}+\\lambda I\\right)^{-1}-\\frac{1}{\\mu_{i}+\\lambda}I\\right)\n",
    "\t=\t\\det\\left(P(D+\\lambda I)^{-1}P^{T}-\\frac{1}{\\mu_{i}+\\lambda}PP^{T}\\right)\n",
    "\t=\t\\det\\left((D+\\lambda I)^{-1}-\\frac{1}{\\mu_{i}+\\lambda}I\\right)\n",
    "\t=\t0 $$\n",
    " \n",
    "\n",
    "Thus the eigenvalues of W\n",
    "  are $ \\frac{1}{\\mu_{1}+\\lambda}\\leq...\\leq\\frac{1}{\\mu_{p}+\\lambda} $\n",
    " ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Theorem\n",
    "\n",
    "Bayes' Theorem is a simple rule about conditional probabilities that has profound consequences.\n",
    "\n",
    "$$ \\mathbb{P}[X=x \\mid Y=y] = \\frac{\\mathbb{P}[Y=y \\mid X=x] \\cdot \\mathbb{P}[X=x]}{\\mathbb{P}[Y=y]} $$\n",
    "\n",
    "Mathematically, it's simply derived from the fact that\n",
    "$$ \\mathbb{P}[X=x\\mid Y=y] \\cdot \\mathbb{P}[Y=y] = \\mathbb{P}[X=x, Y=y] = \\mathbb{P}[Y=y \\mid X=x] \\cdot \\mathbb{P}[X=x] \\,.$$\n",
    "\n",
    "While it seems trivial, it tells us what we know about one variable ($X$) given information about another ($Y$). \n",
    "\n",
    "**Example:** Assume we have  biased Bernoulli $X$ that takes on $1$ with probability $P$.  We don't know $P$; we can call that a random variable as well, and let's assume it's beta distributed with parameters $\\alpha$ and $\\beta$ (denoted $B(\\alpha, \\beta)$).  By observing flips of $X$, we can intuitively infer the value of $P$.\n",
    "\n",
    "Using Bayes' Theorem, we have that the new distribution of\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\mathbb{P}[P=p \\mid X=1] \\propto\\,\\, & \\mathbb{P}[X=1 \\mid P=p] \\cdot \\mathbb{P}[P=p] \\\\\n",
    " \\propto\\,\\, & p p^{\\alpha-1} (1-p)^{\\beta-1} \\\\\n",
    " \\propto\\,\\, & p^{\\alpha} (1-p)^{\\beta-1}\n",
    "\\end{align}\n",
    "$$\n",
    "It's not hard to show that\n",
    "$$ \\mathbb{P}[P=p \\mid X=1] = B(\\alpha+1, \\beta)\\,. $$\n",
    "Similarly, \n",
    "$$ \\mathbb{P}[P=p \\mid X=0] = B(\\alpha, \\beta+1)\\,. $$\n",
    "\n",
    "Stated differently, if we have $P$ distributed as $B(\\alpha, \\beta)$ (the **prior**), and if we observe $X=1$, we update our estimate of the distribution of $P$ (the **posterior**) to $B(\\alpha+1, \\beta)$, and if we observe $X=0$, we update the posterior to $B(\\alpha, \\beta+1)$.  The fact that the Bayes' Theorem equations can be solved in closed form makes the Bernoulli and Beta distributions **Conjugate Priors**.\n",
    "\n",
    "**Example:** We serve ads to individuals, and our prior belief that they will click on an ad is $P$ distributed $B(\\alpha, \\beta)$.  If we see them click on the ad, then our posterior for $P$ is $B(\\alpha+1, \\beta)$, and if they do not, then our posterior is $B(\\alpha, \\beta+1)$.\n",
    "\n",
    "Continuing on, if we show another ad to the same individual, we can get this process to update again.  So if they click on 2 of the 10 ads we show them, then our posterior $P$ is $B(\\alpha+2, \\beta+8)$.\n",
    "\n",
    "In fact, the canonical interpretation of $B(\\alpha, \\beta)$ is our belief about the odds of some $X$ being successful if we have seen $\\alpha$ 1s and $\\beta$ 0s.\n",
    "\n",
    "Below is Bayes' Theorem in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'stats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fccfd0005e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mbinomial_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-fccfd0005e0d>\u001b[0m in \u001b[0;36mbinomial_bayes\u001b[0;34m(a_0, b_0, a_1, b_1)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbinomial_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma_0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ma_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'stats'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "# Beta and binomial are conjugate priors\n",
    "\n",
    "def binomial_bayes(a_0, b_0, a_1, b_1):\n",
    "    prior = sp.stats.beta(a=a_0, b=b_0)\n",
    "    posterior = sp.stats.beta(a=a_0+a_1, b=b_0+b_1)\n",
    "\n",
    "    prior_rvs = prior.rvs(size=10000)\n",
    "    variates = sp.stats.binom(n=a_1+b_1, p=prior_rvs).rvs()\n",
    "    posterior_rvs = prior_rvs[variates == a_1]\n",
    "\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    plot_hist_dist(prior_rvs, prior, title=\"Prior Beta(a={a}, b={b})\".format(**prior.kwds), ax=ax1)\n",
    "    ax2 = plt.subplot(2,1,2, sharex=ax1)\n",
    "    plot_hist_dist(posterior_rvs, posterior, title=\"Posterior Beta(a={a}, b={b})\".format(**posterior.kwds), ax=ax2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "binomial_bayes(a_0=2, b_0=2, a_1=6, b_1=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
